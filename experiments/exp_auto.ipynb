{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import random\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "import pandas as pd\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_mono = np.array([0, -1, -1, -1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input(inputs):\n",
    "    return inputs[:, np.where(mask_mono==0)].squeeze(), \\\n",
    "        inputs[:, np.where(mask_mono!=0)].squeeze() * torch.tensor(mask_mono[np.where(mask_mono!=0)][None,:], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    for _ in trange(num_epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        losses_buffer = []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs_free, inputs_mono = split_input(inputs)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_free.float(), inputs_mono.float())\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            losses_buffer.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total += labels.size(0)\n",
    "        losses.append(np.mean([el.detach().cpu() for el in losses_buffer]))\n",
    "        \n",
    "        val_loss = validate_model(model, val_loader, criterion)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    return losses, val_losses\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs_free, inputs_mono = split_input(inputs)\n",
    "            outputs = model(inputs_free.float(), inputs_mono.float())\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            val_loss += [loss.item()]\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonotonicLinear(nn.Linear):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        bias: bool = True,\n",
    "        device=None, \n",
    "        dtype=None,\n",
    "        pre_activation=nn.Identity(),\n",
    "    ):\n",
    "        super().__init__(in_features, out_features, bias=bias, device=device, dtype=dtype)\n",
    "        self.act = pre_activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        w_pos = self.weight.clamp(min=0.0)\n",
    "        w_neg = self.weight.clamp(max=0.0)\n",
    "        x_pos = F.linear(self.act(x), w_pos, self.bias)\n",
    "        x_neg = F.linear(self.act(-x), w_neg, self.bias)  \n",
    "        return x_pos + x_neg\n",
    "    \n",
    "class MonoModel(torch.nn.Module):\n",
    "    def __init__(self, input_size_mono, num_layers_mono, num_layers_pre_mono, num_neurons_mono, num_neurons_pre_mono, activation=nn.ReLU()) -> None:\n",
    "        super().__init__()\n",
    "        self.pre_mono = torch.nn.ModuleList([torch.nn.LazyLinear(num_neurons_pre_mono) for _ in range(num_layers_pre_mono)])\n",
    "        self.mono = torch.nn.ModuleList(\n",
    "            [\n",
    "                MonotonicLinear(input_size_mono + num_neurons_pre_mono, num_neurons_mono, pre_activation=nn.Identity()),\n",
    "                *[MonotonicLinear(num_neurons_mono, num_neurons_mono, pre_activation=activation) for _ in range(num_layers_mono)],\n",
    "                MonotonicLinear(num_neurons_mono, 1, pre_activation=activation),\n",
    "            ]\n",
    "        )\n",
    "    def forward(self, x, x_mono):\n",
    "        for layer in self.pre_mono:\n",
    "            x = torch.nn.functional.relu(layer(x))\n",
    "        \n",
    "        x = torch.cat((x, x_mono), dim=-1)\n",
    "        for layer in self.mono:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(SEED, n, lr=1e-3, activation=nn.ReLU()):\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    df_train = pd.read_csv('data/train_auto.csv',header = None)\n",
    "    df_train = df_train.dropna(axis=0)        \n",
    "    X_train = df_train.to_numpy()[:,:-1]\n",
    "    y_train = df_train.to_numpy()[:,-1:]\n",
    "\n",
    "    df_val = pd.read_csv('data/test_auto.csv',header = None)\n",
    "    df_val = df_val.dropna(axis=0)\n",
    "    X_val = df_val.to_numpy()[:,:-1]\n",
    "    y_val = df_val.to_numpy()[:,-1:]\n",
    "\n",
    "    X_train = torch.tensor(X_train).to(device).float()\n",
    "    X_val = torch.tensor(X_val).to(device).float()\n",
    "    y_train = torch.tensor(y_train).to(device).float()\n",
    "    y_val = torch.tensor(y_val).to(device).float()\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(TensorDataset(X_train, y_train), batch_size=8, shuffle=True, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(TensorDataset(X_val, y_val), batch_size=8, shuffle=True, drop_last=True)\n",
    "    \n",
    "    model = MonoModel((mask_mono!=0).sum(),3,3, n,n, activation=activation).to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "    losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=300)\n",
    "    print(\"SEED\", SEED, \"VAL LOSS\", np.min(val_losses))\n",
    "    return losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:56<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 0 VAL LOSS 7.126317302385966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:09<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 1 VAL LOSS 8.27412760257721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:58<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 2 VAL LOSS 7.102252960205078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:59<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 3 VAL LOSS 7.074843618604872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:53<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED 4 VAL LOSS 7.1600691477457685\n",
      "---------------------------------\n",
      "Mean 7.347522126303778\n",
      "Std 0.4641505002376592\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 8\n",
    "activation = nn.CELU()\n",
    "train_losses, val_losses = [],[]\n",
    "for seed in range(5):\n",
    "    ltrain, lval = run(seed, n, activation=activation)\n",
    "    train_losses.append(ltrain)\n",
    "    val_losses.append(lval)\n",
    "\n",
    "print(\"---------------------------------\")\n",
    "print(\"Mean\", np.mean([np.min(l) for l in val_losses]))\n",
    "print(\"Std\", np.std([np.min(l) for l in val_losses]))\n",
    "print(\"---------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mono",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
