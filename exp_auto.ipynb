{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    SEED\n",
    "except NameError:\n",
    "    SEED = 0\n",
    "else:\n",
    "    SEED += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import shutil\n",
    "import urllib.request\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from monotonic import MonotonicLinear\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "import optuna\n",
    "import random\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DownloadProgressBar(tqdm):\n",
    "    def update_to(\n",
    "        self, b: int = 1, bsize: int = 1, tsize: Optional[int] = None\n",
    "    ) -> None:\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def _download_url(url: str, output_path: Path) -> None:\n",
    "    with _DownloadProgressBar(\n",
    "        unit=\"B\", unit_scale=True, miniters=1, desc=url.split(\"/\")[-1]\n",
    "    ) as t:\n",
    "        urllib.request.urlretrieve(\n",
    "            url, filename=output_path, reporthook=t.update_to\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data_path(data_path: Optional[Union[Path, str]] = None) -> Path:\n",
    "    if data_path is None:\n",
    "        data_path = \"./data\"\n",
    "    return Path(data_path)\n",
    "def _download_data(\n",
    "    dataset_name: str,\n",
    "    data_path: Optional[Union[Path, str]] = \"data\",\n",
    "    force_download: bool = False,\n",
    ") -> None:\n",
    "    data_path = _get_data_path(data_path)\n",
    "    data_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    for prefix in [\"train\", \"test\"]:\n",
    "        filename = f\"{prefix}_{dataset_name}.csv\"\n",
    "        if not (data_path / filename).exists() or force_download:\n",
    "            with TemporaryDirectory() as d:\n",
    "                _download_url(\n",
    "                    f\"https://zenodo.org/record/7968969/files/{filename}\",\n",
    "                    Path(d) / filename,\n",
    "                )\n",
    "                shutil.copyfile(Path(d) / filename, data_path / filename)\n",
    "        else:\n",
    "            print(f\"Upload skipped, file {(data_path / filename).resolve()} exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sanitize_col_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    columns = {c: c.replace(\" \", \"_\") for c in df}\n",
    "    df = df.rename(columns=columns)\n",
    "    return df\n",
    "def get_data(\n",
    "    dataset_name: str, # \"auto\", \"heart\", compas\", \"blog\", \"loan\"\n",
    "    *,\n",
    "    data_path: Optional[Union[Path, str]] = \"./data\",\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Download data\n",
    "\n",
    "    Args:\n",
    "        dataset_name: name of the dataset, one of \"auto\", \"heart\", compas\", \"blog\", \"loan\"\n",
    "        data_path: root directory where to download data to\n",
    "    \"\"\"\n",
    "    data_path = _get_data_path(data_path)\n",
    "    _download_data(dataset_name=dataset_name, data_path=data_path)\n",
    "\n",
    "    dfx = [\n",
    "        pd.read_csv(data_path / f\"{prefix}_{dataset_name}.csv\")\n",
    "        for prefix in [\"train\", \"test\"]\n",
    "    ]\n",
    "    dfx = [_sanitize_col_names(df) for df in dfx]\n",
    "    return dfx[0], dfx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_mono = np.array([0, -1, -1, -1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input(inputs):\n",
    "    return inputs[:, np.where(1-mask_mono)].squeeze(), \\\n",
    "        inputs[:, np.where(mask_mono)].squeeze() * torch.tensor(mask_mono[np.where(mask_mono)][None,:], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload skipped, file /home/alberto_sinigaglia/jupyter_notebooks/inverseCDF/data/train_auto.csv exists.\n",
      "Upload skipped, file /home/alberto_sinigaglia/jupyter_notebooks/inverseCDF/data/test_auto.csv exists.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "\n",
    "train_df, val_df = get_data(\"auto\")\n",
    "X_train = torch.tensor(train_df.loc[:, train_df.columns != 'ground_truth'].values).to(device)\n",
    "X_val = torch.tensor(val_df.loc[:, val_df.columns != 'ground_truth'].values).to(device)\n",
    "y_train = torch.tensor(train_df.loc[:, train_df.columns == 'ground_truth'].values).to(device)\n",
    "y_val = torch.tensor(val_df.loc[:, val_df.columns == 'ground_truth'].values).to(device)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(TensorDataset(X_train, y_train), batch_size=8, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(TensorDataset(X_val, y_val), batch_size=8, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    best_val_acc = 0.\n",
    "    for epoch in trange(num_epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        losses_buffer = []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs_free, inputs_mono = split_input(inputs)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_free.float(), inputs_mono.float())\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            losses_buffer.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total += labels.size(0)\n",
    "        losses.append(np.mean([el.detach().cpu() for el in losses_buffer]))\n",
    "        \n",
    "        val_loss = validate_model(model, val_loader, criterion)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    return losses, val_losses\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs_free, inputs_mono = split_input(inputs)\n",
    "            outputs = model(inputs_free.float(), inputs_mono.float())\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            val_loss += [loss.item()]\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, input_size_mono, num_layers_mono, num_layers_pre_mono, num_neurons_mono, num_neurons_pre_mono) -> None:\n",
    "        super().__init__()\n",
    "        self.pre_mono = torch.nn.ModuleList([torch.nn.LazyLinear(num_neurons_pre_mono) for _ in range(num_layers_pre_mono)])\n",
    "        self.mono = torch.nn.ModuleList(\n",
    "            [\n",
    "                MonotonicLinear(input_size_mono + num_neurons_pre_mono, num_neurons_mono, pre_activation=nn.Identity()),\n",
    "                *[MonotonicLinear(num_neurons_mono, num_neurons_mono, pre_activation=nn.ReLU()) for _ in range(num_layers_mono)],\n",
    "                MonotonicLinear(num_neurons_mono, 1, pre_activation=nn.ReLU()),\n",
    "            ]\n",
    "        )\n",
    "    def forward(self, x, x_mono):\n",
    "        for layer in self.pre_mono:\n",
    "            x = torch.nn.functional.relu(layer(x))\n",
    "        \n",
    "        x = torch.cat((x, x_mono), dim=-1)\n",
    "        for layer in self.mono:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel((mask_mono!=0).sum(),3,3, 16,16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:07<00:00,  2.66it/s]\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.848956240548028)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
